{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"projet_deep_DenseLayers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"peX7-BZ7K4Kt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b01a5bc8-8aea-4ef9-b2d6-b8a9fbf48aaf","executionInfo":{"status":"ok","timestamp":1576081439664,"user_tz":-60,"elapsed":456,"user":{"displayName":"Qianqiao Liu","photoUrl":"","userId":"00457854431459655603"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":75,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ncSbp4l7Jb1v","colab_type":"code","outputId":"741ac7fe-54fc-4d6c-f2cf-ca3e8074c084","executionInfo":{"status":"error","timestamp":1576077890959,"user_tz":-60,"elapsed":121282,"user":{"displayName":"Qianqiao Liu","photoUrl":"","userId":"00457854431459655603"}},"colab":{"base_uri":"https://localhost:8080/","height":420}},"source":["import pickle\n","import itertools\n","import numpy as np\n","from scipy import spatial\n","from scipy.stats import norm\n","import nltk.data\n","from nltk import pos_tag\n","from nltk.corpus import wordnet as wn\n","from nltk.corpus import reuters\n","from nltk.corpus import gutenberg\n","from nltk.corpus import brown\n","from nltk.tokenize import sent_tokenize\n","from gensim.models import KeyedVectors\n","from keras.layers import Input, Dense, Lambda, Layer\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import Model\n","from keras import backend as K\n","from keras import metrics\n","\n","w2v = KeyedVectors.load_word2vec_format('/content/drive/My Drive/projet_Deep_Learning/wiki-news-300d-1M.vec')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-1dd5ee74538b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mw2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/projet_Deep_Learning/wiki-news-300d-1M.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid vector on line %s (is this really the text format?)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mline_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid vector on line %s (is this really the text format?)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mline_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"d7aam56NJpyY","colab_type":"code","outputId":"cf3d61d8-8cb5-4d19-df20-ab3bb4dd291c","executionInfo":{"status":"ok","timestamp":1576081785357,"user_tz":-60,"elapsed":36740,"user":{"displayName":"Qianqiao Liu","photoUrl":"","userId":"00457854431459655603"}},"colab":{"base_uri":"https://localhost:8080/","height":256}},"source":["import pandas as pd\n","import nltk\n","from nltk.corpus import nps_chat\n","from nltk.corpus import webtext\n","\n","nltk.download('brown')\n","nltk.download('gutenberg')\n","nltk.download('reuters')\n","nltk.download('punkt')\n","nltk.download('webtext')\n","nltk.download('nps_chat')\n","\n","def split_into_sent (text):\n","    strg = ''\n","    for word in text:\n","        strg += word\n","        strg += ' '\n","    strg_cleaned = strg.lower()\n","    for x in ['\\xd5d','\\n','\"',\"!\", '#','$','%','&','(',')','*','+',',','-','/',':',';','<','=','>','?','@','[','^',']','_','`','{','|','}','~','\\t']:\n","        strg_cleaned = strg_cleaned.replace(x, '')\n","    sentences = sent_tokenize(strg_cleaned)\n","    return sentences\n","\n","def vectorize_sentences(sentences):\n","    vectorized = []\n","    for sentence in sentences:\n","        byword = sentence.split()\n","        concat_vector = []\n","        for word in byword:\n","            try:\n","                concat_vector.append(w2v[word])\n","            except:\n","                pass\n","        vectorized.append(concat_vector)\n","    return vectorized\n","\n","data_concat = []\n","for t in [brown.words(), reuters.words(), gutenberg.words(), nps_chat.words(), webtext.words()]:\n","    text = split_into_sent(t)\n","    vect = vectorize_sentences(text)\n","    data = [x for x in vect if len(x) == 10]\n","    for x in data:\n","        data_concat.append(list(itertools.chain.from_iterable(x)))\n","\n","# vectorize the data from set\n","input_texts = []\n","num_input = 5000\n","data_path = \"/content/drive/My Drive/projet_Deep_Learning/train.txt\"\n","with open(data_path, \"r\", encoding=\"utf-8\") as f:\n","    lines = f.read().lower().split(\"\\n\")\n","\n","for line in lines[0:(num_input - 1)]:\n","\n","    input_text = split_into_sent(line)\n","    vect = vectorize_sentences(input_text)\n","    data = [x for x in vect if len(x) == 10]\n","    for x in data:\n","        data_concat.append(list(itertools.chain.from_iterable(x)))\n","\n","\n","data_array = np.array(data_concat)\n","np.random.shuffle(data_array)\n","print(\"nombre de phrases : \",len(data_array))\n","train = data_array[:8000]\n","test = data_array[8000:8500]\n"],"execution_count":80,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n","[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n","[nltk_data] Downloading package reuters to /root/nltk_data...\n","[nltk_data]   Package reuters is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package webtext to /root/nltk_data...\n","[nltk_data]   Package webtext is already up-to-date!\n","[nltk_data] Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]   Package nps_chat is already up-to-date!\n","nombre de phrases :  8533\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"praqwwZxJrCu","colab_type":"code","outputId":"cc699bb1-723d-4f21-ea99-f712ea31afde","executionInfo":{"status":"ok","timestamp":1576082199216,"user_tz":-60,"elapsed":188699,"user":{"displayName":"Qianqiao Liu","photoUrl":"","userId":"00457854431459655603"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras import callbacks\n","batch_size = 100\n","original_dim = 3000\n","latent_dim = 1000\n","intermediate_dim = 1200\n","epochs = 100\n","epsilon_std = 1.0\n","\n","x = Input(batch_shape=(batch_size, original_dim))\n","h = Dense(intermediate_dim, activation='relu')(x)\n","z_mean = Dense(latent_dim)(h)\n","z_log_var = Dense(latent_dim)(h)\n","\n","def sampling(args):\n","    z_mean, z_log_var = args\n","    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n","                              stddev=epsilon_std)\n","    return z_mean + K.exp(z_log_var / 2) * epsilon\n","\n","# note that \"output_shape\" isn't necessary with the TensorFlow backend\n","z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n","\n","# we instantiate these layers separately so as to reuse them later\n","decoder_h = Dense(intermediate_dim, activation='relu')\n","decoder_mean = Dense(original_dim, activation='sigmoid')\n","h_decoded = decoder_h(z)\n","x_decoded_mean = decoder_mean(h_decoded)\n","\n","# placeholder loss\n","def zero_loss(y_true, y_pred):\n","    return K.zeros_like(y_pred)\n","\n","# Custom loss layer\n","class CustomVariationalLayer(Layer):\n","    def __init__(self, **kwargs):\n","        self.is_placeholder = True\n","        super(CustomVariationalLayer, self).__init__(**kwargs)\n","\n","    def vae_loss(self, x, x_decoded_mean):\n","        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n","        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n","        return K.mean(xent_loss + kl_loss)\n","\n","    def call(self, inputs):\n","        x = inputs[0]\n","        x_decoded_mean = inputs[1]\n","        loss = self.vae_loss(x, x_decoded_mean)\n","        self.add_loss(loss, inputs=inputs)\n","        # we don't use this output, but it has to have the correct shape:\n","        return K.ones_like(x)\n","\n","loss_layer = CustomVariationalLayer()([x, x_decoded_mean])\n","vae = Model(x, [loss_layer])\n","vae.compile(optimizer='rmsprop', loss=[zero_loss])\n","\n","#checkpoint\n","cp = [callbacks.ModelCheckpoint(filepath=\"/content/drive/My Drive/projet_Deep_Learning/model.h5\", verbose=1, save_best_only=True)]\n","\n","#train\n","vae.fit(train, train,\n","        shuffle=True,\n","        epochs=epochs,\n","        batch_size=batch_size,\n","        validation_data=(test, test), callbacks=cp)\n","\n","# build a model to project inputs on the latent space\n","encoder = Model(x, z_mean)\n","\n","# build a generator that can sample from the learned distribution\n","decoder_input = Input(shape=(latent_dim,))\n","_h_decoded = decoder_h(decoder_input)\n","_x_decoded_mean = decoder_mean(_h_decoded)\n","generator = Model(decoder_input, _x_decoded_mean)\n","\n"],"execution_count":82,"outputs":[{"output_type":"stream","text":["Train on 8000 samples, validate on 500 samples\n","Epoch 1/100\n","8000/8000 [==============================] - 3s 322us/step - loss: -449.7148 - val_loss: -566.8231\n","\n","Epoch 00001: val_loss improved from inf to -566.82307, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 2/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -593.1020 - val_loss: -647.1553\n","\n","Epoch 00002: val_loss improved from -566.82307 to -647.15532, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 3/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -645.9731 - val_loss: -667.5177\n","\n","Epoch 00003: val_loss improved from -647.15532 to -667.51768, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 4/100\n","8000/8000 [==============================] - 2s 201us/step - loss: -655.7478 - val_loss: -672.7039\n","\n","Epoch 00004: val_loss improved from -667.51768 to -672.70387, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 5/100\n","8000/8000 [==============================] - 2s 202us/step - loss: -661.7342 - val_loss: -677.2176\n","\n","Epoch 00005: val_loss improved from -672.70387 to -677.21759, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 6/100\n","8000/8000 [==============================] - 2s 203us/step - loss: -666.9650 - val_loss: -681.1680\n","\n","Epoch 00006: val_loss improved from -677.21759 to -681.16799, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 7/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -672.1365 - val_loss: -686.6873\n","\n","Epoch 00007: val_loss improved from -681.16799 to -686.68727, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 8/100\n","8000/8000 [==============================] - 2s 202us/step - loss: -676.5721 - val_loss: -689.9004\n","\n","Epoch 00008: val_loss improved from -686.68727 to -689.90037, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 9/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -680.3141 - val_loss: -692.2239\n","\n","Epoch 00009: val_loss improved from -689.90037 to -692.22391, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 10/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -684.3067 - val_loss: -697.9205\n","\n","Epoch 00010: val_loss improved from -692.22391 to -697.92046, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 11/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -687.6116 - val_loss: -702.0304\n","\n","Epoch 00011: val_loss improved from -697.92046 to -702.03038, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 12/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -691.8379 - val_loss: -703.8671\n","\n","Epoch 00012: val_loss improved from -702.03038 to -703.86714, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 13/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -695.3744 - val_loss: -708.8882\n","\n","Epoch 00013: val_loss improved from -703.86714 to -708.88820, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 14/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -698.8414 - val_loss: -709.0517\n","\n","Epoch 00014: val_loss improved from -708.88820 to -709.05168, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 15/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -701.2506 - val_loss: -712.7130\n","\n","Epoch 00015: val_loss improved from -709.05168 to -712.71300, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 16/100\n","8000/8000 [==============================] - 2s 202us/step - loss: -704.0402 - val_loss: -713.8290\n","\n","Epoch 00016: val_loss improved from -712.71300 to -713.82897, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 17/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -706.7541 - val_loss: -717.1441\n","\n","Epoch 00017: val_loss improved from -713.82897 to -717.14407, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 18/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -710.0091 - val_loss: -721.8423\n","\n","Epoch 00018: val_loss improved from -717.14407 to -721.84227, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 19/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -712.7598 - val_loss: -723.9443\n","\n","Epoch 00019: val_loss improved from -721.84227 to -723.94427, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 20/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -715.4125 - val_loss: -725.9940\n","\n","Epoch 00020: val_loss improved from -723.94427 to -725.99404, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 21/100\n","8000/8000 [==============================] - 2s 203us/step - loss: -717.5892 - val_loss: -727.3949\n","\n","Epoch 00021: val_loss improved from -725.99404 to -727.39486, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 22/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -720.2844 - val_loss: -729.3887\n","\n","Epoch 00022: val_loss improved from -727.39486 to -729.38872, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 23/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -722.2977 - val_loss: -731.8938\n","\n","Epoch 00023: val_loss improved from -729.38872 to -731.89377, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 24/100\n","8000/8000 [==============================] - 2s 202us/step - loss: -724.6261 - val_loss: -734.1686\n","\n","Epoch 00024: val_loss improved from -731.89377 to -734.16860, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 25/100\n","8000/8000 [==============================] - 2s 200us/step - loss: -726.7268 - val_loss: -737.9917\n","\n","Epoch 00025: val_loss improved from -734.16860 to -737.99167, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 26/100\n","8000/8000 [==============================] - 2s 202us/step - loss: -728.7957 - val_loss: -737.9677\n","\n","Epoch 00026: val_loss did not improve from -737.99167\n","Epoch 27/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -731.1086 - val_loss: -739.8252\n","\n","Epoch 00027: val_loss improved from -737.99167 to -739.82524, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 28/100\n","8000/8000 [==============================] - 2s 200us/step - loss: -732.6374 - val_loss: -740.5955\n","\n","Epoch 00028: val_loss improved from -739.82524 to -740.59547, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 29/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -734.6508 - val_loss: -742.5373\n","\n","Epoch 00029: val_loss improved from -740.59547 to -742.53729, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 30/100\n","8000/8000 [==============================] - 2s 200us/step - loss: -736.7469 - val_loss: -743.4748\n","\n","Epoch 00030: val_loss improved from -742.53729 to -743.47478, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 31/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -738.4946 - val_loss: -746.0962\n","\n","Epoch 00031: val_loss improved from -743.47478 to -746.09624, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 32/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -740.6418 - val_loss: -748.1885\n","\n","Epoch 00032: val_loss improved from -746.09624 to -748.18853, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 33/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -742.6998 - val_loss: -749.5633\n","\n","Epoch 00033: val_loss improved from -748.18853 to -749.56334, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 34/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -744.6786 - val_loss: -749.9299\n","\n","Epoch 00034: val_loss improved from -749.56334 to -749.92992, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 35/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -746.5161 - val_loss: -753.4437\n","\n","Epoch 00035: val_loss improved from -749.92992 to -753.44374, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 36/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -748.4222 - val_loss: -752.2371\n","\n","Epoch 00036: val_loss did not improve from -753.44374\n","Epoch 37/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -750.3786 - val_loss: -754.1666\n","\n","Epoch 00037: val_loss improved from -753.44374 to -754.16660, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 38/100\n","8000/8000 [==============================] - 2s 201us/step - loss: -751.9834 - val_loss: -755.7954\n","\n","Epoch 00038: val_loss improved from -754.16660 to -755.79543, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 39/100\n","8000/8000 [==============================] - 2s 202us/step - loss: -753.3338 - val_loss: -756.7569\n","\n","Epoch 00039: val_loss improved from -755.79543 to -756.75688, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 40/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -755.0699 - val_loss: -759.9470\n","\n","Epoch 00040: val_loss improved from -756.75688 to -759.94698, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 41/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -756.6234 - val_loss: -761.2264\n","\n","Epoch 00041: val_loss improved from -759.94698 to -761.22642, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 42/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -758.0444 - val_loss: -762.0221\n","\n","Epoch 00042: val_loss improved from -761.22642 to -762.02206, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 43/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -759.6345 - val_loss: -763.1465\n","\n","Epoch 00043: val_loss improved from -762.02206 to -763.14655, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 44/100\n","8000/8000 [==============================] - 2s 200us/step - loss: -761.1056 - val_loss: -764.4002\n","\n","Epoch 00044: val_loss improved from -763.14655 to -764.40021, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 45/100\n","8000/8000 [==============================] - 2s 200us/step - loss: -762.5453 - val_loss: -766.4207\n","\n","Epoch 00045: val_loss improved from -764.40021 to -766.42072, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 46/100\n","8000/8000 [==============================] - 2s 203us/step - loss: -763.7733 - val_loss: -766.7082\n","\n","Epoch 00046: val_loss improved from -766.42072 to -766.70824, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 47/100\n","8000/8000 [==============================] - 2s 204us/step - loss: -765.6764 - val_loss: -767.3838\n","\n","Epoch 00047: val_loss improved from -766.70824 to -767.38381, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 48/100\n","8000/8000 [==============================] - 2s 203us/step - loss: -766.8192 - val_loss: -769.0588\n","\n","Epoch 00048: val_loss improved from -767.38381 to -769.05878, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 49/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -768.1541 - val_loss: -769.2762\n","\n","Epoch 00049: val_loss improved from -769.05878 to -769.27625, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 50/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -769.4897 - val_loss: -771.4795\n","\n","Epoch 00050: val_loss improved from -769.27625 to -771.47947, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 51/100\n","8000/8000 [==============================] - 2s 202us/step - loss: -771.2292 - val_loss: -772.6886\n","\n","Epoch 00051: val_loss improved from -771.47947 to -772.68861, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 52/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -772.0303 - val_loss: -771.5221\n","\n","Epoch 00052: val_loss did not improve from -772.68861\n","Epoch 53/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -773.7050 - val_loss: -774.5896\n","\n","Epoch 00053: val_loss improved from -772.68861 to -774.58961, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 54/100\n","8000/8000 [==============================] - 2s 203us/step - loss: -775.0261 - val_loss: -775.0678\n","\n","Epoch 00054: val_loss improved from -774.58961 to -775.06776, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 55/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -776.1925 - val_loss: -776.8243\n","\n","Epoch 00055: val_loss improved from -775.06776 to -776.82430, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 56/100\n","8000/8000 [==============================] - 2s 201us/step - loss: -777.5248 - val_loss: -776.3750\n","\n","Epoch 00056: val_loss did not improve from -776.82430\n","Epoch 57/100\n","8000/8000 [==============================] - 2s 194us/step - loss: -778.5332 - val_loss: -777.2211\n","\n","Epoch 00057: val_loss improved from -776.82430 to -777.22112, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 58/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -779.7448 - val_loss: -778.0578\n","\n","Epoch 00058: val_loss improved from -777.22112 to -778.05784, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 59/100\n","8000/8000 [==============================] - 2s 200us/step - loss: -781.4435 - val_loss: -779.3084\n","\n","Epoch 00059: val_loss improved from -778.05784 to -779.30837, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 60/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -782.6796 - val_loss: -781.4814\n","\n","Epoch 00060: val_loss improved from -779.30837 to -781.48140, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 61/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -783.5583 - val_loss: -781.0135\n","\n","Epoch 00061: val_loss did not improve from -781.48140\n","Epoch 62/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -785.1565 - val_loss: -782.7728\n","\n","Epoch 00062: val_loss improved from -781.48140 to -782.77279, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 63/100\n","8000/8000 [==============================] - 2s 202us/step - loss: -786.2621 - val_loss: -781.5966\n","\n","Epoch 00063: val_loss did not improve from -782.77279\n","Epoch 64/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -787.2518 - val_loss: -785.1392\n","\n","Epoch 00064: val_loss improved from -782.77279 to -785.13918, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 65/100\n","8000/8000 [==============================] - 2s 200us/step - loss: -788.4088 - val_loss: -785.0564\n","\n","Epoch 00065: val_loss did not improve from -785.13918\n","Epoch 66/100\n","8000/8000 [==============================] - 2s 194us/step - loss: -789.4155 - val_loss: -786.1582\n","\n","Epoch 00066: val_loss improved from -785.13918 to -786.15820, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 67/100\n","8000/8000 [==============================] - 2s 200us/step - loss: -790.7572 - val_loss: -785.8453\n","\n","Epoch 00067: val_loss did not improve from -786.15820\n","Epoch 68/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -791.9881 - val_loss: -786.1405\n","\n","Epoch 00068: val_loss did not improve from -786.15820\n","Epoch 69/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -793.2865 - val_loss: -787.2107\n","\n","Epoch 00069: val_loss improved from -786.15820 to -787.21071, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 70/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -794.2537 - val_loss: -788.1568\n","\n","Epoch 00070: val_loss improved from -787.21071 to -788.15680, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 71/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -795.5260 - val_loss: -790.2138\n","\n","Epoch 00071: val_loss improved from -788.15680 to -790.21382, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 72/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -796.7224 - val_loss: -790.0224\n","\n","Epoch 00072: val_loss did not improve from -790.21382\n","Epoch 73/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -797.7545 - val_loss: -791.3975\n","\n","Epoch 00073: val_loss improved from -790.21382 to -791.39753, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 74/100\n","8000/8000 [==============================] - 2s 200us/step - loss: -798.8950 - val_loss: -791.0051\n","\n","Epoch 00074: val_loss did not improve from -791.39753\n","Epoch 75/100\n","8000/8000 [==============================] - 2s 199us/step - loss: -799.7093 - val_loss: -791.7466\n","\n","Epoch 00075: val_loss improved from -791.39753 to -791.74656, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 76/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -800.2781 - val_loss: -792.7883\n","\n","Epoch 00076: val_loss improved from -791.74656 to -792.78832, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 77/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -801.3463 - val_loss: -794.8702\n","\n","Epoch 00077: val_loss improved from -792.78832 to -794.87024, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 78/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -802.5806 - val_loss: -796.0811\n","\n","Epoch 00078: val_loss improved from -794.87024 to -796.08113, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 79/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -803.5775 - val_loss: -794.4367\n","\n","Epoch 00079: val_loss did not improve from -796.08113\n","Epoch 80/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -804.9391 - val_loss: -795.8304\n","\n","Epoch 00080: val_loss did not improve from -796.08113\n","Epoch 81/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -805.7291 - val_loss: -797.7748\n","\n","Epoch 00081: val_loss improved from -796.08113 to -797.77483, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 82/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -806.4704 - val_loss: -795.7742\n","\n","Epoch 00082: val_loss did not improve from -797.77483\n","Epoch 83/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -807.6457 - val_loss: -797.2316\n","\n","Epoch 00083: val_loss did not improve from -797.77483\n","Epoch 84/100\n","8000/8000 [==============================] - 2s 193us/step - loss: -808.8793 - val_loss: -799.9513\n","\n","Epoch 00084: val_loss improved from -797.77483 to -799.95132, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 85/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -809.4823 - val_loss: -798.8061\n","\n","Epoch 00085: val_loss did not improve from -799.95132\n","Epoch 86/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -810.5664 - val_loss: -799.7368\n","\n","Epoch 00086: val_loss did not improve from -799.95132\n","Epoch 87/100\n","8000/8000 [==============================] - 2s 193us/step - loss: -811.7777 - val_loss: -800.7212\n","\n","Epoch 00087: val_loss improved from -799.95132 to -800.72117, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 88/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -812.8478 - val_loss: -801.4278\n","\n","Epoch 00088: val_loss improved from -800.72117 to -801.42778, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 89/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -813.9056 - val_loss: -802.9755\n","\n","Epoch 00089: val_loss improved from -801.42778 to -802.97549, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 90/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -814.5000 - val_loss: -803.8760\n","\n","Epoch 00090: val_loss improved from -802.97549 to -803.87595, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 91/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -816.0664 - val_loss: -802.7518\n","\n","Epoch 00091: val_loss did not improve from -803.87595\n","Epoch 92/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -816.3036 - val_loss: -802.6756\n","\n","Epoch 00092: val_loss did not improve from -803.87595\n","Epoch 93/100\n","8000/8000 [==============================] - 2s 194us/step - loss: -817.5001 - val_loss: -803.8454\n","\n","Epoch 00093: val_loss did not improve from -803.87595\n","Epoch 94/100\n","8000/8000 [==============================] - 2s 195us/step - loss: -818.0919 - val_loss: -804.7683\n","\n","Epoch 00094: val_loss improved from -803.87595 to -804.76830, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 95/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -818.9267 - val_loss: -805.3237\n","\n","Epoch 00095: val_loss improved from -804.76830 to -805.32366, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 96/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -819.9972 - val_loss: -806.0618\n","\n","Epoch 00096: val_loss improved from -805.32366 to -806.06183, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 97/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -821.1176 - val_loss: -804.1627\n","\n","Epoch 00097: val_loss did not improve from -806.06183\n","Epoch 98/100\n","8000/8000 [==============================] - 2s 196us/step - loss: -822.1004 - val_loss: -805.8750\n","\n","Epoch 00098: val_loss did not improve from -806.06183\n","Epoch 99/100\n","8000/8000 [==============================] - 2s 197us/step - loss: -823.2428 - val_loss: -808.7007\n","\n","Epoch 00099: val_loss improved from -806.06183 to -808.70073, saving model to /content/drive/My Drive/projet_Deep_Learning/model.h5\n","Epoch 100/100\n","8000/8000 [==============================] - 2s 198us/step - loss: -823.7534 - val_loss: -807.5949\n","\n","Epoch 00100: val_loss did not improve from -808.70073\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wXS4NgirjZev","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":495},"outputId":"550d9dcf-803d-4b10-89b7-263eb8a7f051","executionInfo":{"status":"ok","timestamp":1576077735807,"user_tz":-60,"elapsed":453,"user":{"displayName":"Qianqiao Liu","photoUrl":"","userId":"00457854431459655603"}}},"source":["vae.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (100, 3000)          0                                            \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (100, 1200)          3601200     input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (100, 1000)          1201000     dense_11[0][0]                   \n","__________________________________________________________________________________________________\n","dense_13 (Dense)                (100, 1000)          1201000     dense_11[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (100, 1000)          0           dense_12[0][0]                   \n","                                                                 dense_13[0][0]                   \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                multiple             1201200     lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                multiple             3603000     dense_14[0][0]                   \n","__________________________________________________________________________________________________\n","custom_variational_layer_2 (Cus [(100, 3000), (100,  0           input_3[0][0]                    \n","                                                                 dense_15[0][0]                   \n","==================================================================================================\n","Total params: 10,807,400\n","Trainable params: 10,807,400\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UG76wdYkKKgz","colab_type":"code","colab":{}},"source":["# some matrix magic\n","def sent_parse(sentence, mat_shape):\n","    data_concat = []\n","    word_vecs = vectorize_sentences(sentence)\n","    for x in word_vecs:\n","        data_concat.append(list(itertools.chain.from_iterable(x)))\n","    zero_matr = np.zeros(mat_shape)\n","    zero_matr[0] = np.array(data_concat)\n","    return zero_matr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"97UvdQNuKOPU","colab_type":"code","colab":{}},"source":["# input: original dimension sentence vector\n","# output: text\n","def print_sentence_with_w2v(sent_vect):\n","    word_sent = ''\n","    tocut = sent_vect\n","    for i in range (int(len(sent_vect)/300)):\n","        word_sent += w2v.most_similar(positive=[tocut[:300]], topn=1)[0][0]\n","        word_sent += ' '\n","        tocut = tocut[300:]\n","    print(word_sent)\n","\n","# input: encoded sentence vector\n","# output: encoded sentence vector in dataset with highest cosine similarity\n","def find_similar_encoding(sent_vect):\n","    all_cosine = []\n","    for sent in sent_encoded:\n","        result = 1 - spatial.distance.cosine(sent_vect, sent)\n","        all_cosine.append(result)\n","    data_array = np.array(all_cosine)\n","    \n","    maximum = data_array.argsort()[-3:][::-1][1]\n","    print(maximum)\n","    new_vec = sent_encoded[maximum]\n","    return new_vec\n","\n","# input: two points, integer n\n","# output: n equidistant points on the line between the input points (inclusive)\n","def shortest_homology(point_one, point_two, num):\n","    dist_vec = point_two - point_one\n","    sample = np.linspace(0, 1, num, endpoint = True)\n","    hom_sample = []\n","    for s in sample:\n","        hom_sample.append(point_one + s * dist_vec)\n","    return hom_sample\n","\n","\n","# input: two written sentences, VAE batch-size, dimension of VAE input\n","# output: the function embeds the sentences in latent-space, and then prints their generated text representations\n","# along with the text representations of several points in between them\n","def sent_2_sent(sent1,sent2, batch, dim):\n","    a = sent_parse([sent1], (batch,dim))\n","    b = sent_parse([sent2], (batch,dim))\n","    encode_a = encoder.predict(a, batch_size = batch)\n","    encode_b = encoder.predict(b, batch_size = batch)\n","    test_hom = hom_shortest(encode_a[0], encode_b[0], 5)\n","    \n","    for point in test_hom:\n","        p = generator.predict(np.array([point]))[0]\n","        print_sentence(p)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0gLOHVBPKpFT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":606},"outputId":"73dd61be-e154-4119-b8f2-723b4b4f925a","executionInfo":{"status":"ok","timestamp":1576083185365,"user_tz":-60,"elapsed":28519,"user":{"displayName":"Qianqiao Liu","photoUrl":"","userId":"00457854431459655603"}}},"source":["print_sentence_with_w2v(train[4789])\n","sent_encoded = encoder.predict(np.array(train), batch_size = 100)\n","sent_decoded = generator.predict(sent_encoded)\n","test_hom1 = shortest_homology(sent_encoded[4789], sent_encoded[88], 10)\n","\n","print(\"---phrases originales---\")\n","print_sentence_with_w2v(train[4789])\n","print_sentence_with_w2v(train[88])\n","print(\"---phrases decodées distribuées uniformément---\")\n","for point in test_hom1:\n","    p = generator.predict(np.array([point]))[0]\n","    print_sentence_with_w2v(p)\n","\n","print(\"---phrases originales---\")\n","print_sentence_with_w2v(train[7111])\n","print_sentence_with_w2v(train[1312])\n","test_hom2 = shortest_homology(sent_encoded[7111], sent_encoded[1312], 5)\n","print(\"---phrases décodées les plus proches---\")\n","for point in test_hom2:\n","    p = generator.predict(np.array([find_similar_encoding(point)]))[0]\n","    print_sentence_with_w2v(p)"],"execution_count":92,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"stream","text":["a word with you attend those men our pleasure . \n","---phrases originales---\n","a word with you attend those men our pleasure . \n","i w a s r e a d y . \n","---phrases decodées distribuées uniformément---\n","of man of do even one nature of sorrow . \n","of man of we even one kind of sorrow . \n","one tho of just one one kind of dear . \n","just tho of just one one one of man . \n","i c a one th e equal a f . \n","i w a s l e c e f . \n","i w a s l e c e f . \n","i w a s r e c e y . \n","i w a s r e c e y . \n","i w a s r e c e y . \n","---phrases originales---\n","und westbank to reorganize network und westbank ag lt . \n","elton but i have not much faith in mrs . \n","---phrases décodées les plus proches---\n","7062\n","english water a direct global tho oil ltd lt . \n","7062\n","english water a direct global tho oil ltd lt . \n","1312\n","jason say i have not more for of mrs . \n","7524\n","elizabeth could not not not little one of mrs . \n","7002\n","i say i have even a truly kind lady . \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"__DXPcy6XIbN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"e388d674-e70c-41ff-e94d-c93a6967b206","executionInfo":{"status":"ok","timestamp":1576078462094,"user_tz":-60,"elapsed":646,"user":{"displayName":"Qianqiao Liu","photoUrl":"","userId":"00457854431459655603"}}},"source":["senten1 = ['Hello','world','have','to','run']\n","senten2 = ['Hello','back']\n","def inserer_sen(sent1,sent2):\n","  sent1_vec = []\n","  sent2_vec = []\n","  for word in sent1:\n","    sent1_vec.append(w2v[word])\n","\n","  for word in sent2:\n","    sent2_vec.append(w2v[word])\n","\n","  return sent1_vec, sent2_vec\n","\n","sent1_vec, sent2_vec = inserer_sen(senten1,senten2)\n","print(\"sent1\")\n","print_sentence_with_w2v(sent1_vec)\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["sent1\n","\n"],"name":"stdout"}]}]}